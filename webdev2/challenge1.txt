LLm integration error

Access to fetch at 'https://togetherai-backend.vercel.app/api/chat' from origin 'https://benjamindavisdc.github.io' has been blocked by CORS policy: Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource. If an opaque response serves your needs, set the request's mode to 'no-cors' to fetch the resource with CORS disabled.
togetherai-backend.vercel.app/api/chat:1 
        
        
    Failed to load resource: net::ERR_FAILED
script.js:61 Error sending message: TypeError: Failed to fetch
    at sendMessageToBackend (script.js:44:32)
    at HTMLFormElement.<anonymous> (script.js:85:9)




Visiting my backend directly kept giving me an error

500: INTERNAL_SERVER_ERROR
Code: FUNCTION_INVOCATION_FAILED
ID: dev1::dev1::bkbvt-1739052840551-78299961fc8d

And the error logs read:
{"error":"Method Not Allowed"}

I looked through the logic of my chat app:

            // Send back the AI response to the frontend
            res.status(200).json({ response: aiResponse });

        } catch (error) {
            console.error('Error with Together API:', error);
            res.status(500).json({ error: 'Failed to get response from Together API' });
        }
    } else {
        // If it's not a POST request, respond with 405 (Method Not Allowed)
        res.status(405).json({ error: 'Method Not Allowed' });
    }

and the "Method not allowed" error wasn't really an error, it is the expected response when looked at by the browser, since browsers GET rather than POST, when the function is actually called.